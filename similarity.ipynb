{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "similarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulri_ndZlNlk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "415470d0-9563-4f13-c8ad-ecf43eec9836"
      },
      "source": [
        "cd drive/My\\ Drive/app/EGR590"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/app/EGR590\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeBPy71JinwK"
      },
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZesyEGdulPm"
      },
      "source": [
        "0 - original,\n",
        "1 - random,\n",
        "2 - close,\n",
        "3 - far"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15rVU_2bq-85"
      },
      "source": [
        "preproced_docs =[]\n",
        "for file in Path(\"./preproc\").rglob(\"*.txt\"):\n",
        "    with open(file) as f:\n",
        "        txt_file_as_string = f.read()\n",
        "    preproced_docs.append(txt_file_as_string)\n",
        "\n",
        "base_document = preproced_docs[0]\n",
        "documents = preproced_docs[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdyZvr7Uu9Ix",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e8c13255-7c46-47dd-c2c3-cf7ef460e4aa"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "reference = base_document\n",
        "comparison_docs = documents\n",
        "\n",
        "def process_tfidf_similarity():\n",
        "  vectorizer = TfidfVectorizer()\n",
        "\n",
        "\t# To make uniformed vectors, both documents need to be combined first.\n",
        "  embeddings = vectorizer.fit_transform(preproced_docs)\n",
        "  \n",
        "  cosine_similarities = cosine_similarity(embeddings[0:1], embeddings[0:]).flatten()\n",
        "  \n",
        "  highest_score = 0\n",
        "  highest_score_index = 0\n",
        "  \n",
        "  for i, score in enumerate(cosine_similarities):\n",
        "    print(i, score)\n",
        "    if highest_score < score:\n",
        "      highest_score = score\n",
        "      highest_score_index = i\n",
        "  \n",
        "  most_similar_document_rem = documents[highest_score_index]\n",
        "  \n",
        "  print(\"Most similar document by TF-IDF with the score:\", highest_score_index, highest_score)\n",
        "\n",
        "process_tfidf_similarity()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1.0\n",
            "1 0.8829193112698767\n",
            "2 0.9015492352341855\n",
            "3 0.7004992765627059\n",
            "Most similar document by TF-IDF with the score: 0 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaT41V4E1a83"
      },
      "source": [
        "#!wget \"https://tfhub.dev/google/universal-sentence-encoder/4?tf-hub-format=compressed\" universal-sentence-encoder_4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4WFgwaG2QKI"
      },
      "source": [
        "#!tar -xvf 4?tf-hub-format=compressed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJM1CbzfzCh-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b12c5952-8879-49d3-c6ad-6ddefa5d2594"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "def process_use_similarity():\n",
        "  filename = \"./USEmodel\"\n",
        "  model = hub.load(filename)\n",
        "  \n",
        "  base_embeddings = model([base_document])\n",
        "  \n",
        "  embeddings = model(preproced_docs)\n",
        "  \n",
        "  scores = cosine_similarity(base_embeddings, embeddings).flatten()\n",
        "  \n",
        "  highest_score = 0\n",
        "  highest_score_index = 0\n",
        "  for i, score in enumerate(scores):\n",
        "    print(i, score)\n",
        "    if highest_score < score:\n",
        "      highest_score = score\n",
        "      highest_score_index = i\n",
        "      \n",
        "  most_similar_document = documents[highest_score_index]\n",
        "  print(\"Most similar document by USE with the score:\", highest_score_index, highest_score)\n",
        "\n",
        "process_use_similarity()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1.0\n",
            "1 0.44078398\n",
            "2 0.5280792\n",
            "3 0.43918502\n",
            "Most similar document by USE with the score: 0 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPhSbUzKAfNK"
      },
      "source": [
        "ABOVE: Universal Sentence Encoder: https://arxiv.org/abs/1803.11175\n",
        "Pretrained model from: https://tfhub.dev/google/universal-sentence-encoder/4 (the latest pretrained model available, updated 2020)\n",
        "\n",
        "While originally meant for generation of sentence-level embeddings, the model does not actually require a set maximum sequence length. It directly uses the encoding sub-graph of the original transformer architecture\n",
        "\n",
        "Our hypothesis is that since it creates a single embedding at runtime for the entire input sequence, this perhaps allows for better context-aware representations to be learned.\n",
        "\n",
        "The observed similarity scores seem to corroborate this since the model outputs much more discriminatory embeddings than the other candidates. Notice that the text determined as 'close' (class 2) to the reference text (class 0) by human experts, while indeed the closest, still shows a cosine similarity of only 0.528. Further, the texts determined as 'random' (class 1) and 'far' (class 3) are also significantly further from 'close' as well as the reference text, but very close to each other - which is what we might expect from a model which has learnt semantic relationships particularly well (after all, why should Pride and Prejudice be closer to Robinson Crusoe than (BOOK FAR.txt)? - both are unrelated by plot). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jebJqL7m9a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d370a50b-d24d-4137-aeda-c7a0de207e67"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def process_bert_similarity():\n",
        "  model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "  sentences = sent_tokenize(base_document)\n",
        "  base_embeddings_sentences = model.encode(sentences)\n",
        "  base_embeddings = np.mean(np.array(base_embeddings_sentences), axis=0)\n",
        "  \n",
        "  vectors = []\n",
        "  \n",
        "  for i, document in enumerate(documents):\n",
        "    sentences = sent_tokenize(document)\n",
        "    embeddings_sentences = model.encode(sentences)\n",
        "    embeddings = np.mean(np.array(embeddings_sentences), axis=0)\n",
        "    \n",
        "    vectors.append(embeddings)\n",
        "    print(\"making vector at index:\", i)\n",
        "    \n",
        "  vectors.insert(0, base_embeddings)\n",
        "  scores = cosine_similarity([base_embeddings], vectors).flatten()\n",
        "    \n",
        "  highest_score = 0\n",
        "  highest_score_index = 0\n",
        "  for i, score in enumerate(scores):\n",
        "    print(i, score)\n",
        "    if highest_score < score:\n",
        "      highest_score = score\n",
        "      highest_score_index = i\n",
        "  \n",
        "  most_similar_document = documents[highest_score_index]\n",
        "  print(\"Most similar document by BERT with the score:\", highest_score_index, highest_score)\n",
        "\n",
        "process_bert_similarity()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "making vector at index: 0\n",
            "making vector at index: 1\n",
            "making vector at index: 2\n",
            "0 1.0000002\n",
            "1 0.827144\n",
            "2 0.90516925\n",
            "3 0.6855231\n",
            "Most similar document by BERT with the score: 0 1.0000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKKF8m7kS2_a"
      },
      "source": [
        "ABOVE: We get embeddings using BERT (https://arxiv.org/abs/1810.04805). We use UKPLab's implementation (https://github.com/UKPLab/sentence-transformers). We choose to tokenize each text into sentences first because sentences are still a semantically meaningful unit by themselves. We do this because that important information might be lost if we allow BERT to automatically truncate the input sequence after a max length of 512 tokens. \n",
        "\n",
        "If Tfidf might be considered the least discriminatory, and USE the most, then BERT falls in the middle. This behavious makes sense since we have averaged the sentence embeddings to get the book embedding, and thus the contextual information learnt is actually at the sentence-level and then naively averaged out. As a result, while the 'random' text (class 1) is still further than 'close', it is much closer to the reference text than 'far'. We hypothesize that this is due to the nature of the sentence-level embeddings - the representation learnt is more about the similarity in the stylistic/ linguistic/ grammatical/ lexical sense than about the plot. (After all Pride and Prejudice is from a much closer era to Robinson Crusoe, and reads much like what a reader might expect of a 'classic' text).\n",
        "\n",
        "The question is, for our model, how much more should the plot matter than the style/ grammar/ lexicon etc for deciding similarity, if indeed it should?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axffob45kOKZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}